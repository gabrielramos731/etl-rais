{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c196de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fa09b",
   "metadata": {},
   "source": [
    "# RAIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5cd04",
   "metadata": {},
   "source": [
    "## Estabelecimentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44b0770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_estb(caminho, ano)-> pd.DataFrame:\n",
    "    try: # txt file\n",
    "        colunas = ['CNAE 2.0 Classe', 'Município']\n",
    "        df_estb = pd.read_csv(caminho + 'ESTB' + ano + '.txt', sep=';', encoding='latin1', usecols=colunas)\n",
    "        df_estb['ano'] = ano\n",
    "        extensao_arquivo = 'txt'\n",
    "        \n",
    "    except: # csv file\n",
    "        colunas = ['ano', 'id_municipio', 'cnae_2']\n",
    "        df_estb = pd.read_csv(caminho + 'ESTB' + ano + '.csv', usecols=colunas)\n",
    "        extensao_arquivo = 'csv'\n",
    "\n",
    "    return df_estb, extensao_arquivo\n",
    "\n",
    "def read_data_vinc(caminho, ano, uf)-> pd.DataFrame:\n",
    "    colunas = ['CNAE 2.0 Classe', 'Município']\n",
    "    df_vinc = pd.read_csv(f'{caminho}{ano}/{uf}', sep=';', encoding='latin1', usecols=colunas)  # voltar para cá a cada UF\n",
    "    df_vinc['ano'] = ano\n",
    "\n",
    "    return df_vinc, 'txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8acb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, extensao) -> pd.DataFrame:\n",
    "    '''Normaliza o tipo de cada coluna e obtem a cnae_secao de cnae_2'''\n",
    "    \n",
    "    if extensao == 'txt':\n",
    "        df.rename(columns={'Município': 'id_municipio', 'CNAE 2.0 Classe': 'cnae_2'}, inplace=True)\t\n",
    "        df = df[['ano', 'id_municipio', 'cnae_2']]\n",
    "        df.dropna(inplace=True)\n",
    "    elif extensao == 'csv':\n",
    "        df.dropna(inplace=True)\n",
    "        df['id_municipio'] = df['id_municipio'].astype('int')\n",
    "        df['id_municipio'] = df['id_municipio'].apply(lambda x: int(x/10)) # remove 7'th dígito\n",
    "    \n",
    "    # para todos\n",
    "    df['ano'] = df['ano'].astype('int16')\n",
    "    \n",
    "    df['id_municipio'] = df['id_municipio'].astype('int')\n",
    "    \n",
    "    df.loc[:, 'cnae_2'] = df['cnae_2'].apply(lambda x: str(x).zfill(5))\n",
    "    df['cnae_secao'] = df['cnae_2'].apply(lambda x: x[:2])\n",
    "    df['cnae_secao'] = df['cnae_secao'].astype('int')\n",
    "    df.drop(columns=['cnae_2'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1cc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_municipios(df, caminho, loc) -> pd.DataFrame:\n",
    "    '''Faz o merge do id_municipio com os dados do dicionário'''\n",
    "    \n",
    "    if loc == 'mesorregiao':\n",
    "        colunas_muni = ['id_municipio_6', 'sigla_uf', 'id_mesorregiao', 'nome_mesorregiao']\n",
    "    elif loc == 'microrregiao':\n",
    "        colunas_muni = ['id_municipio_6', 'sigla_uf', 'id_microrregiao', 'nome_microrregiao', 'id_mesorregiao']\n",
    "    elif loc == 'municipio':\n",
    "        colunas_muni = ['id_municipio_6', 'sigla_uf', 'centroide', 'nome', 'id_microrregiao']\n",
    "    dicionario_muni = pd.read_csv(caminho, sep=',', usecols=colunas_muni)\n",
    "    dicionario_muni.rename(columns={'id_municipio_6': 'id_municipio', 'nome': 'municipio'}, inplace=True)\n",
    "    \n",
    "    df = pd.merge(df, dicionario_muni, on='id_municipio', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6048c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cnae(df, caminho) -> pd.DataFrame:\n",
    "    \n",
    "    colunas_tmp = ['divisao', 'descricao_secao', 'descricao_divisao']\n",
    "    df_cnae = pd.read_csv(caminho, usecols=colunas_tmp)\n",
    "    df_cnae.rename(columns={'divisao': 'cnae_secao'}, inplace=True)\n",
    "    df_cnae.drop_duplicates(inplace=True)   \n",
    "    \n",
    "    df = pd.merge(df, df_cnae, on='cnae_secao', how='left')\n",
    "    df.drop(columns=['cnae_secao'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aab8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ql(df, indice, loc) -> pd.DataFrame:\n",
    "    \n",
    "    if loc == 'mesorregiao':\n",
    "        numerador_est = df.groupby(['ano', 'sigla_uf', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf', 'id_mesorregiao']).size()\n",
    "        denominador_est = df.groupby(['ano', 'sigla_uf', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf']).size()\n",
    "        ql_est = numerador_est / denominador_est\n",
    "        ql_est = ql_est.reset_index()\n",
    "        ql_est.drop(columns=['sigla_uf'], inplace=True)\n",
    "        ql_est.columns = ['ano', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao', f'{indice}_est']\n",
    "        \n",
    "        numerador_nac = df.groupby(['ano', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_mesorregiao']).size()\n",
    "        denominador_nac = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql_nac = numerador_nac / denominador_nac\n",
    "        ql_nac = ql_nac.reset_index()\n",
    "        ql_nac.columns = ['ano', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao', f'{indice}_nac']\n",
    "        \n",
    "        \n",
    "    elif loc == 'microrregiao':\n",
    "        numerador_est = df.groupby(['ano', 'sigla_uf', 'id_microrregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf', 'id_microrregiao']).size()\n",
    "        denominador_est = df.groupby(['ano', 'sigla_uf', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf']).size()\n",
    "        ql_est = numerador_est / denominador_est\n",
    "        ql_est = ql_est.reset_index()\n",
    "        ql_est.drop(columns=['sigla_uf'], inplace=True)\n",
    "        ql_est.columns = ['ano', 'id_microrregiao', 'descricao_secao', 'descricao_divisao', f'{indice}_est']\n",
    "        \n",
    "        numerador_nac = df.groupby(['ano', 'id_microrregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_microrregiao']).size()\n",
    "        denominador_nac = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql_nac = numerador_nac / denominador_nac\n",
    "        ql_nac = ql_nac.reset_index()\n",
    "        ql_nac.columns = ['ano', 'id_microrregiao', 'descricao_secao', 'descricao_divisao', f'{indice}_nac']\n",
    "        \n",
    "    elif loc == 'municipio':\n",
    "        numerador_est = df.groupby(['ano', 'sigla_uf', 'id_municipio', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf', 'id_municipio']).size()\n",
    "        denominador_est = df.groupby(['ano', 'sigla_uf', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'sigla_uf']).size()\n",
    "        ql_est = numerador_est / denominador_est\n",
    "        ql_est = ql_est.reset_index()\n",
    "        ql_est.drop(columns=['sigla_uf'], inplace=True)\n",
    "        ql_est.columns = ['ano', 'id_municipio', 'descricao_secao', 'descricao_divisao', f'{indice}_est']\n",
    "        \n",
    "        numerador_nac = df.groupby(['ano', 'id_municipio', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_municipio']).size()\n",
    "        denominador_nac = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql_nac = numerador_nac / denominador_nac\n",
    "        ql_nac = ql_nac.reset_index()\n",
    "        ql_nac.columns = ['ano', 'id_municipio', 'descricao_secao', 'descricao_divisao', f'{indice}_nac']\n",
    "        \n",
    "    \n",
    "    df_tmp = pd.merge(ql_est, ql_nac, on=['ano', f'id_{loc}', 'descricao_secao', 'descricao_divisao'], how='outer')\n",
    "    df_tmp[f'{indice}_nac'] = df_tmp[f'{indice}_nac'].map(lambda x: float(f\"{x:.2f}\"))\n",
    "    df_tmp[f'{indice}_est'] = df_tmp[f'{indice}_est'].map(lambda x: float(f\"{x:.2f}\"))\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22367792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def etl_pipeline(caminhos, ano_ini, ano_fim, loc):\n",
    "   \n",
    "    dfs_ql = []\n",
    "    dfs_qe = []\n",
    "    \n",
    "    # indice ql\n",
    "    for ano in range(ano_ini, ano_fim+1):\n",
    "        df, extensao = read_data_estb(caminhos['rais'][0], str(ano))\n",
    "        df = transform_data(df, extensao)\n",
    "        df = merge_municipios(df, caminhos['municipios'], loc)\n",
    "        df = merge_cnae(df, caminhos['cnae'])\n",
    "        \n",
    "        dfs_ql.append(calc_ql(df, indice='ql', loc=loc))  # estb anual\n",
    "\n",
    "    # indice qe\n",
    "    for ano in range(ano_ini, ano_fim+1):\n",
    "        ufs = os.listdir(os.path.join(caminhos['rais'][1], str(ano)))\n",
    "        for arq_uf in ufs:\n",
    "            df, extensao = read_data_vinc(caminhos['rais'][1], str(ano), arq_uf)\n",
    "            df = transform_data(df, extensao)\n",
    "            df = merge_municipios(df, caminhos['municipios'], loc)\n",
    "            df = merge_cnae(df, caminhos['cnae'])\n",
    "            \n",
    "            dfs_qe.append(calc_ql(df, indice='qe', loc=loc))\n",
    "    \n",
    "    dfs_ql = pd.concat(dfs_ql)\n",
    "    dfs_qe = pd.concat(dfs_qe)\n",
    "    df = pd.merge(dfs_ql, dfs_qe, on=['ano', f'id_{loc}', 'descricao_secao', 'descricao_divisao'], how='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882d50f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defdcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "def processar_loc(loc):\n",
    "    \n",
    "    df_ql = etl_pipeline(caminhos, ano_ini, ano_fim, loc=loc)\n",
    "    path_out = Path(f\"C:/dev/ndti/rais/indices2/divisao/fact_div_{loc}.csv\")\n",
    "    path_out.parent.mkdir(exist_ok=True)\n",
    "    df_ql.to_csv(path_out, sep=';', index=False)\n",
    "    return loc\n",
    "\n",
    "# Parâmetros globais\n",
    "caminho_estb = \"D:/dados/rais/estabelecimentos/\"\n",
    "caminho_vinc = \"D:/dados/rais/vinculos/extraidos/\"\n",
    "caminho_dict_muni = \"D:/dados/rais/dicionarios/dicionario_municipios.csv\"\n",
    "caminho_dict_cnae = \"D:/dados/rais/dicionarios/dicionario_cnae_2.csv\"\n",
    "ano_ini = 2007\n",
    "ano_fim = 2024\n",
    "caminhos = {'rais': [caminho_estb, caminho_vinc], \n",
    "            'municipios': caminho_dict_muni, \n",
    "            'cnae': caminho_dict_cnae}\n",
    "\n",
    "resultados = Parallel(n_jobs=3)(delayed(processar_loc)(loc) for loc in ['municipio'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb180ed",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
