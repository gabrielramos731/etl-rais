{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c196de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fa09b",
   "metadata": {},
   "source": [
    "# RAIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5cd04",
   "metadata": {},
   "source": [
    "## Estabelecimentos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd2bb3",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Realizar cálculos de seção e divisão em uma única execução\n",
    "\n",
    "- Implementação sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b0770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(caminho, ano)-> pd.DataFrame:\n",
    "    '''Read the ESTB data from a file and return a DataFrame.'''\n",
    "    try: # txt file\n",
    "        colunas = ['CNAE 2.0 Classe', 'Município']\n",
    "        df_estb = pd.read_csv(caminho + 'ESTB' + ano + '.txt', sep=';', encoding='latin1', usecols=colunas)\n",
    "        df_estb['ano'] = ano\n",
    "        extensao_arquivo = 'txt'\n",
    "        \n",
    "    except: # csv file\n",
    "        colunas = ['ano', 'id_municipio', 'cnae_2']\n",
    "        df_estb = pd.read_csv(caminho + 'ESTB' + ano + '.csv', usecols=colunas)\n",
    "        extensao_arquivo = 'csv'\n",
    "\n",
    "    return df_estb, extensao_arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8acb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, extensao) -> pd.DataFrame:\n",
    "    '''Normaliza o tipo de cada coluna e obtem a cnae_secao de cnae_2'''\n",
    "    \n",
    "    if extensao == 'txt':\n",
    "        df.rename(columns={'Município': 'id_municipio', 'CNAE 2.0 Classe': 'cnae_2'}, inplace=True)\t\n",
    "        df = df[['ano', 'id_municipio', 'cnae_2']]\n",
    "    elif extensao == 'csv':\n",
    "        df.dropna(inplace=True)\n",
    "        df['id_municipio'] = df['id_municipio'].astype('int')\n",
    "        df['id_municipio'] = df['id_municipio'].apply(lambda x: int(x/10)) # remove 7'th dígito\n",
    "    \n",
    "    # para todos\n",
    "    df['ano'] = df['ano'].astype('int16')\n",
    "    \n",
    "    df['id_municipio'] = df['id_municipio'].astype('int')\n",
    "    \n",
    "    df.loc[:, 'cnae_2'] = df['cnae_2'].apply(lambda x: str(x).zfill(5))\n",
    "    df['cnae_secao'] = df['cnae_2'].apply(lambda x: x[:2])\n",
    "    df['cnae_secao'] = df['cnae_secao'].astype('int')\n",
    "    df.drop(columns=['cnae_2'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a1cc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_municipios(df, caminho, loc) -> pd.DataFrame:\n",
    "    '''Faz o merge do id_municipio com os dados do dicionário'''\n",
    "    \n",
    "    if loc == 'meso':\n",
    "        colunas_muni = ['id_municipio_6', 'id_mesorregiao', 'nome_mesorregiao']\n",
    "    elif loc == 'micro':\n",
    "        colunas_muni = ['id_municipio_6', 'id_microrregiao', 'nome_microrregiao', 'id_mesorregiao']\n",
    "    elif loc == 'muni':\n",
    "        colunas_muni = ['id_municipio_6', 'centroide', 'nome', 'id_microrregiao']\n",
    "    dicionario_muni = pd.read_csv(caminho, sep=',', usecols=colunas_muni)\n",
    "    dicionario_muni.rename(columns={'id_municipio_6': 'id_municipio', 'nome': 'municipio'}, inplace=True)\n",
    "    \n",
    "    df = pd.merge(df, dicionario_muni, on='id_municipio', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6048c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cnae(df, caminho) -> pd.DataFrame:\n",
    "    '''Faz o merge do cnae_secao com os dados do dicionário'''\n",
    "    \n",
    "    colunas_tmp = ['divisao','descricao_secao', 'descricao_divisao']\n",
    "    df_cnae = pd.read_csv(caminho, usecols=colunas_tmp)\n",
    "    df_cnae.rename(columns={'divisao': 'cnae_secao'}, inplace=True)\n",
    "    df_cnae.drop_duplicates(inplace=True)   \n",
    "    \n",
    "    df = pd.merge(df, df_cnae, on='cnae_secao', how='left')\n",
    "    df.drop(columns=['cnae_secao'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ql(df, loc='meso') -> pd.DataFrame:\n",
    "    '''\n",
    "    Calcula o quociente de localização para níveis de meso, microrregião ou município tendo o estado como setor de referência\n",
    "    loc= 'meso', 'micro' ou 'muni'\n",
    "    '''\n",
    "    \n",
    "    if loc == 'meso':\n",
    "        numerador = df.groupby(['ano', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_mesorregiao']).size()\n",
    "        denominador = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql = numerador / denominador\n",
    "        ql = ql.reset_index()\n",
    "        ql.columns = ['ano', 'id_mesorregiao', 'descricao_secao', 'descricao_divisao', 'quociente_localizacao']\n",
    "        \n",
    "    elif loc == 'micro':\n",
    "        numerador = df.groupby(['ano', 'id_microrregiao', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_microrregiao']).size()\n",
    "        denominador = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql = numerador / denominador\n",
    "        ql = ql.reset_index()\n",
    "        ql.columns = ['ano', 'id_microrregiao', 'descricao_secao', 'descricao_divisao', 'quociente_localizacao']\n",
    "        \n",
    "    elif loc == 'muni':\n",
    "        numerador = df.groupby(['ano', 'id_municipio', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano', 'id_municipio']).size()\n",
    "        denominador = df.groupby(['ano', 'descricao_secao', 'descricao_divisao']).size() / df.groupby(['ano']).size()\n",
    "        ql = numerador / denominador\n",
    "        ql = ql.reset_index()\n",
    "        ql.columns = ['ano', 'id_municipio', 'descricao_secao', 'descricao_divisao', 'quociente_localizacao']\n",
    "\n",
    "    ql['quociente_localizacao'] = ql['quociente_localizacao'].map(lambda x: float(f\"{x:.2f}\"))\n",
    "\n",
    "    return ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22367792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_pipeline(caminhos, ano_ini, ano_fim, loc):\n",
    "    '''\n",
    "    Executa o pipeline ETL para os dados de estabelecimentos da RAIS.\n",
    "\n",
    "    Parâmetros:\n",
    "        caminhos (dict): Dicionário com os caminhos dos arquivos de dados e dicionários.\n",
    "        ano_ini (int): Ano inicial do processamento.\n",
    "        ano_fim (int): Ano final do processamento.\n",
    "        loc (str): Nível de localização para o cálculo do quociente de localização ('meso', 'micro' ou 'muni').\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame com o quociente de localização calculado para o(s) ano(s) e nível selecionados.\n",
    "    '''\n",
    "    dfs_ql = []\n",
    "    for ano in range(ano_ini, ano_fim+1):\n",
    "        print('---', ano, '---')\n",
    "        df, extensao = read_data(caminhos['rais'], str(ano))\n",
    "        df = transform_data(df, extensao)\n",
    "        df = merge_municipios(df, caminhos['municipios'], loc)\n",
    "        df = merge_cnae(df, caminhos['cnae'])\n",
    "        \n",
    "        dfs_ql.append(calc_ql(df, loc))\n",
    "    df = pd.concat(dfs_ql)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882d50f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "def processar_loc(loc):\n",
    "    \n",
    "    df_ql = etl_pipeline(caminhos, ano_ini, ano_fim, loc)\n",
    "    path_out = Path(f\"indices_ql_teste/indice_ql_divisao_{loc}.csv\")\n",
    "    path_out.parent.mkdir(exist_ok=True)\n",
    "    df_ql.to_csv(path_out, sep=';', index=False)\n",
    "    print(f'--- {loc} concluído ---')\n",
    "    return loc\n",
    "\n",
    "# Parâmetros globais\n",
    "caminho = \"D:/dados/rais/estabelecimentos/\"\n",
    "caminho_dict_muni = \"./dicionarios/dicionario_municipios.csv\"\n",
    "caminho_dict_cnae = \"./dicionarios/dicionario_cnae_2.csv\"\n",
    "ano_ini = 2007\n",
    "ano_fim = 2024\n",
    "caminhos = {'rais': caminho, \n",
    "            'municipios': caminho_dict_muni, \n",
    "            'cnae': caminho_dict_cnae}\n",
    "\n",
    "resultados = Parallel(n_jobs=3)(delayed(processar_loc)(loc) for loc in ['meso', 'micro', 'muni'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb180ed",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
